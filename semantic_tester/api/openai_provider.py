"""
OpenAI AI ä¾›åº”å•†å®ç°

å®ç° OpenAI API çš„è¯­ä¹‰ç›¸ä¼¼åº¦æ£€æŸ¥åŠŸèƒ½ï¼Œç»§æ‰¿è‡ª AIProvider æŠ½è±¡åŸºç±»ã€‚
æ”¯æŒ OpenAI å®˜æ–¹ API å’Œå…¼å®¹æ¥å£ã€‚
"""

import json
import logging
import threading
import time
from typing import List, Dict, Optional, Any

try:
    import openai
    from openai import OpenAI
except ImportError as e:
    raise ImportError("è¯·å®‰è£… OpenAI SDK: pip install openai") from e

try:
    from colorama import Fore, Style  # type: ignore
except ImportError:
    # å¦‚æœ colorama ä¸å¯ç”¨ï¼Œå®šä¹‰ç©ºçš„é¢œè‰²å’Œæ ·å¼
    class Fore:  # type: ignore[no-redef]
        GREEN = ""
        RED = ""

    class Style:  # type: ignore[no-redef]
        BRIGHT = ""
        RESET_ALL = ""


from .base_provider import AIProvider


from .prompts import SEMANTIC_CHECK_PROMPT

logger = logging.getLogger(__name__)


class OpenAIProvider(AIProvider):
    """OpenAI AI ä¾›åº”å•†"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ– OpenAI ä¾›åº”å•†

        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å« api_keys, model, base_url ç­‰ä¿¡æ¯
        """
        super().__init__(config)

        self.api_keys = config.get("api_keys", [])
        self.model_name = config.get("model", "gpt-4o")
        self.base_url = config.get("base_url", "https://api.openai.com/v1")
        self.has_config = config.get("has_config", len(self.api_keys) > 0)

        # å†…éƒ¨çŠ¶æ€
        self.client = None
        self.current_key_index = 0
        self.key_last_used_time: Dict[str, float] = {}
        self.key_cooldown_until: Dict[str, float] = {}
        self.first_actual_call = True

        # åˆå§‹åŒ–å¯ç”¨å¯†é’¥å’Œå®¢æˆ·ç«¯
        self._initialize_api_keys()
        self._configure_client()

    def get_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        return [
            "gpt-4o",
            "gpt-4o-mini",
            "o1",  # æ¨ç†æ¨¡å‹ï¼Œæ”¯æŒæ€ç»´é“¾
            "o1-mini",  # è½»é‡æ¨ç†æ¨¡å‹
            "o1-preview",  # æ¨ç†é¢„è§ˆæ¨¡å‹
            "gpt-4-turbo",
            "gpt-3.5-turbo",
            "gpt-4",
        ]

    def validate_api_key(self, api_key: str) -> bool:
        """
        éªŒè¯ API å¯†é’¥æœ‰æ•ˆæ€§

        Args:
            api_key: API å¯†é’¥

        Returns:
            bool: å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
        """
        if not api_key.startswith("sk-"):
            logger.warning(f"OpenAI API Key æ ¼å¼æ— æ•ˆ: {api_key[:10]}...")
            return False

        try:
            test_client = OpenAI(api_key=api_key, base_url=self.base_url)
            # å°è¯•è·å–æ¨¡å‹åˆ—è¡¨æ¥éªŒè¯å¯†é’¥
            test_client.models.list()
            return True
        except Exception as e:
            logger.warning(f"OpenAI API Key éªŒè¯å¤±è´¥: {e}")
            return False

    def is_configured(self) -> bool:
        """æ£€æŸ¥ä¾›åº”å•†æ˜¯å¦å·²æ­£ç¡®é…ç½®"""
        return len(self.api_keys) > 0 and self.client is not None

    def check_semantic_similarity(
        self,
        question: str,
        ai_answer: str,
        source_document: str,
        model: Optional[str] = None,
        stream: bool = False,
        show_thinking: bool = False,
    ) -> tuple[str, str]:
        """
        æ‰§è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦æ£€æŸ¥

        Args:
            question: é—®é¢˜å†…å®¹
            ai_answer: AIå›ç­”å†…å®¹
            source_document: æºæ–‡æ¡£å†…å®¹
            model: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            show_thinking: æ˜¯å¦æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹ï¼ˆä»…o1ç³»åˆ—æ¨¡å‹æœ‰æ•ˆï¼‰

        Returns:
            tuple[str, str]: (ç»“æœ, åŸå› )ï¼Œç»“æœä¸º"æ˜¯"/"å¦"/"é”™è¯¯"
        """
        if not self.is_configured():
            return "é”™è¯¯", "OpenAI ä¾›åº”å•†æœªæ­£ç¡®é…ç½®"

        model_to_use = model or self.model_name
        prompt = self._get_prompt(question, ai_answer, source_document)

        max_retries = 3
        default_retry_delay = 30

        for attempt in range(max_retries):

            # åˆ›å»ºç­‰å¾…æŒ‡ç¤ºå™¨
            stop_event = threading.Event()
            waiting_thread = threading.Thread(
                target=self.show_waiting_indicator, args=(stop_event,)
            )
            waiting_thread.daemon = True

            # åªæœ‰åœ¨éæµå¼æ¨¡å¼æ‰æ˜¾ç¤ºç­‰å¾…æŒ‡ç¤ºå™¨
            if not stream:
                waiting_thread.start()

            try:
                result, reason = self._call_openai_api(
                    model_to_use,
                    prompt,
                    attempt,
                    max_retries,
                    default_retry_delay,
                    stream,
                    show_thinking,
                    stop_event,
                )
                if result != "RETRY":
                    return result, reason

            except Exception as e:
                logger.error(f"è°ƒç”¨ OpenAI API æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                if attempt < max_retries - 1:
                    time.sleep(default_retry_delay)
                    continue
                else:
                    return "é”™è¯¯", f"API è°ƒç”¨å¤šæ¬¡é‡è¯•å¤±è´¥: {e}"

            finally:
                stop_event.set()
                if waiting_thread.is_alive():
                    waiting_thread.join(timeout=0.5)

        return "é”™è¯¯", "API è°ƒç”¨å¤šæ¬¡é‡è¯•å¤±è´¥"

    def _call_openai_api(  # noqa: C901
        self,
        model_to_use: str,
        prompt: str,
        attempt: int,
        max_retries: int,
        default_retry_delay: int,
        stream: bool = False,
        show_thinking: bool = False,
        stop_event: Optional[threading.Event] = None,
    ) -> tuple[str, str]:
        """
        è°ƒç”¨ OpenAI API å¹¶å¤„ç†å“åº”

        Returns:
            tuple[str, str]: (ç»“æœ, åŸå› ) æˆ– ("RETRY", "") è¡¨ç¤ºéœ€è¦é‡è¯•
        """
        import sys

        logger.info(
            f"æ­£åœ¨è°ƒç”¨ OpenAI API è¿›è¡Œè¯­ä¹‰æ¯”å¯¹ (å°è¯• {attempt + 1}/{max_retries})..."
        )

        # è·å–å¯ç”¨å®¢æˆ·ç«¯
        client = self._get_available_client()
        if not client:
            logger.warning("æ— å¯ç”¨ OpenAI å®¢æˆ·ç«¯ï¼Œè·³è¿‡ API è°ƒç”¨")
            if attempt < max_retries - 1:
                return "RETRY", ""
            else:
                return "é”™è¯¯", "æ— å¯ç”¨ OpenAI æ¨¡å‹"

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨ç†æ¨¡å‹ï¼ˆo1ç³»åˆ—ï¼‰
        is_reasoning_model = model_to_use.startswith("o1")

        try:
            if stream and not is_reasoning_model:
                # æµå¼è°ƒç”¨ï¼ˆo1ç³»åˆ—ä¸æ”¯æŒæµå¼ï¼‰
                response = client.chat.completions.create(
                    model=model_to_use,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­ä¹‰åˆ†æåŠ©æ‰‹ã€‚"},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0,
                    max_tokens=1000,
                    stream=True,
                )

                # åœæ­¢ç­‰å¾…æŒ‡ç¤ºå™¨
                if stop_event:
                    stop_event.set()

                full_response = ""
                first_char_printed = False

                logger.info("å¼€å§‹æ¥æ”¶æµå¼å“åº”...")

                for chunk in response:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content

                        if not first_char_printed:
                            sys.stdout.write(f"\r{' ' * 50}\r")
                            sys.stdout.write("OpenAI: ")
                            sys.stdout.flush()
                            first_char_printed = True

                        print(content, end="", flush=True)
                        full_response += content

                if first_char_printed:
                    print()

                response_text = full_response.strip()
            else:
                # éæµå¼è°ƒç”¨æˆ–æ¨ç†æ¨¡å‹
                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­ä¹‰åˆ†æåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": prompt},
                ]

                # o1ç³»åˆ—æ¨¡å‹ä¸æ”¯æŒsystemæ¶ˆæ¯å’Œtemperature
                if is_reasoning_model:
                    messages = [{"role": "user", "content": prompt}]
                    response = client.chat.completions.create(
                        model=model_to_use,
                        messages=messages,
                        max_completion_tokens=1000,
                    )
                else:
                    response = client.chat.completions.create(
                        model=model_to_use,
                        messages=messages,
                        temperature=0,
                        max_tokens=1000,
                    )

                if not response.choices or not response.choices[0].message.content:
                    logger.warning("OpenAI API è¿”å›ç©ºå“åº”")
                    return "é”™è¯¯", "API è¿”å›ç©ºå“åº”"

                # æå–æ¨ç†è¿‡ç¨‹ï¼ˆä»…o1ç³»åˆ—ï¼‰
                if is_reasoning_model and show_thinking:
                    try:
                        # o1 ç³»åˆ—æ¨¡å‹ä¼šåœ¨ completion_tokens_details ä¸­åŒ…å« reasoning_tokens
                        choice = response.choices[0]
                        if (
                            hasattr(choice.message, "reasoning_content")
                            and choice.message.reasoning_content
                        ):
                            from rich.panel import Panel
                            from rich.markdown import Markdown
                            from rich import print as rprint
                            
                            rprint(Panel(
                                Markdown(choice.message.reasoning_content),
                                title="[bold blue]ğŸ’­ æ¨ç†è¿‡ç¨‹[/bold blue]",
                                border_style="bright_cyan",
                                expand=False
                            ))
                        elif hasattr(response, "usage"):
                            usage = response.usage
                            if hasattr(usage, "completion_tokens_details"):
                                details = usage.completion_tokens_details
                                if hasattr(details, "reasoning_tokens") and details.reasoning_tokens > 0:
                                    logger.info(
                                        f"\nğŸ’­ æ¨ç†tokensæ•°: {details.reasoning_tokens}\n"
                                    )
                    except Exception as e:
                        logger.debug(f"æå–æ¨ç†å†…å®¹å¤±è´¥: {e}")

                response_text = response.choices[0].message.content.strip()

            return self._parse_response(response_text)

        except openai.AuthenticationError as e:
            logger.error(f"OpenAI API è®¤è¯å¤±è´¥: {e}")
            return "é”™è¯¯", f"API è®¤è¯å¤±è´¥: {e}"

        except openai.RateLimitError as e:
            logger.warning(f"OpenAI API é€Ÿç‡é™åˆ¶: {e}")
            if attempt < max_retries - 1:
                retry_after = self._extract_retry_delay(str(e)) or default_retry_delay
                logger.info(f"ç­‰å¾… {retry_after} ç§’åé‡è¯•")
                time.sleep(retry_after)
                return "RETRY", ""
            else:
                return "é”™è¯¯", "API è°ƒç”¨æ¬¡æ•°è¶…é™"

        except openai.APIError as e:
            logger.error(f"OpenAI API é”™è¯¯: {e}")
            if attempt < max_retries - 1:
                time.sleep(default_retry_delay)
                return "RETRY", ""
            else:
                return "é”™è¯¯", f"API è°ƒç”¨å¤±è´¥: {e}"

    def _parse_response(self, response_text: str) -> tuple[str, str]:
        """
        è§£æ API å“åº”

        Args:
            response_text: API è¿”å›çš„å“åº”æ–‡æœ¬

        Returns:
            tuple[str, str]: (ç»“æœ, åŸå› )
        """
        # å°è¯•è§£æ JSON å“åº”
        try:
            # å¦‚æœå“åº”åŒ…å«ä»£ç å—ï¼Œæå–å…¶ä¸­çš„ JSON
            if response_text.startswith("```json") and response_text.endswith("```"):
                response_text = response_text[7:-3].strip()
            elif response_text.startswith("```") and response_text.endswith("```"):
                response_text = response_text[3:-3].strip()

            parsed_response = json.loads(response_text)
            result = parsed_response.get("result", "æ— æ³•åˆ¤æ–­").strip()
            reason = parsed_response.get("reason", "æ— ").strip()

            self._log_result(result)
            return result, reason

        except json.JSONDecodeError:
            # å¦‚æœ JSON è§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–ç»“æœ
            if "æ˜¯" in response_text and "å¦" not in response_text:
                result = "æ˜¯"
                reason = response_text
            elif "å¦" in response_text and "æ˜¯" not in response_text:
                result = "å¦"
                reason = response_text
            else:
                result = "æ— æ³•åˆ¤æ–­"
                reason = f"æ— æ³•è§£æå“åº”: {response_text[:200]}..."

            self._log_result(result, text_mode=True)
            return result, reason

    def _log_result(self, result: str, text_mode: bool = False) -> None:
        """
        è®°å½•è¯­ä¹‰æ¯”å¯¹ç»“æœ

        Args:
            result: è¯­ä¹‰æ¯”å¯¹ç»“æœ
            text_mode: æ˜¯å¦ä¸ºæ–‡æœ¬è§£ææ¨¡å¼
        """
        colored_result = result
        if result == "æ˜¯":
            colored_result = Style.BRIGHT + Fore.GREEN + result + Style.RESET_ALL
        elif result == "å¦":
            colored_result = Style.BRIGHT + Fore.RED + result + Style.RESET_ALL

        mode_text = "ï¼ˆæ–‡æœ¬è§£æï¼‰" if text_mode else ""
        logger.info(f"è¯­ä¹‰æ¯”å¯¹ç»“æœ{mode_text}ï¼š{colored_result}")

    def _get_prompt(
        self, question: str, ai_answer: str, source_document_content: str
    ) -> str:
        """ç”Ÿæˆè¯­ä¹‰æ¯”å¯¹æç¤ºè¯"""
        return SEMANTIC_CHECK_PROMPT.format(
            question=question,
            ai_answer=ai_answer,
            source_document=source_document_content,
        )

    def _initialize_api_keys(self):
        """åˆå§‹åŒ– API å¯†é’¥åˆ—è¡¨ï¼ˆå¯åŠ¨æ—¶è·³è¿‡éªŒè¯ï¼‰"""
        if not self.api_keys:
            logger.debug("OpenAI API å¯†é’¥æœªé…ç½®")
            return

        current_time = time.time()
        for key in self.api_keys:
            self.key_last_used_time[key] = current_time
            self.key_cooldown_until[key] = 0.0

        logger.debug(f"å·²åˆå§‹åŒ– {len(self.api_keys)} ä¸ª OpenAI API å¯†é’¥")

    def _configure_client(self):
        """é…ç½® OpenAI å®¢æˆ·ç«¯"""
        if not self.api_keys:
            self.client = None
            return

        current_api_key = self.api_keys[self.current_key_index]
        try:
            self.client = OpenAI(
                api_key=current_api_key, base_url=self.base_url, timeout=60
            )
            logger.debug(
                f"OpenAI API å®¢æˆ·ç«¯å·²é…ç½®ï¼Œä½¿ç”¨å¯†é’¥ç´¢å¼•: {self.current_key_index}"
            )
            self.key_last_used_time[current_api_key] = time.time()
        except Exception as e:
            logger.error(f"OpenAI API é…ç½®å¤±è´¥: {e}")
            self.client = None
            if self.api_keys:
                self._rotate_key(force_rotate=True)

    def _get_available_client(self):
        """è·å–å¯ç”¨çš„å®¢æˆ·ç«¯"""
        if not self.api_keys:
            return None

        self._rotate_key()
        return self.client

    def _rotate_key(self, force_rotate: bool = False):
        """è½®è½¬åˆ°ä¸‹ä¸€ä¸ª API å¯†é’¥"""
        if not self.api_keys:
            return

        # å¦‚æœæœªå¯ç”¨è‡ªåŠ¨è½®è½¬ä¸”ä¸æ˜¯å¼ºåˆ¶è½®è½¬ï¼Œåˆ™ä¸è¿›è¡Œè½®è½¬
        if not self.auto_rotate and not force_rotate:
            return

        current_time = time.time()

        for _ in range(len(self.api_keys)):
            self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
            next_key = self.api_keys[self.current_key_index]

            cooldown_until = self.key_cooldown_until.get(next_key, 0.0)
            cooldown_remaining = max(0.0, cooldown_until - current_time)
            time_since_last_use = current_time - self.key_last_used_time.get(
                next_key, 0.0
            )

            if force_rotate:
                logger.info(f"å¼ºåˆ¶è½®è½¬: æ–°å¯†é’¥ç´¢å¼•: {self.current_key_index}")
                self.key_last_used_time[next_key] = current_time
                self._configure_client()
                return

            if cooldown_remaining <= 0:
                if self.first_actual_call:
                    logger.info(f"é¦–æ¬¡å®é™…è°ƒç”¨ï¼Œå¯†é’¥ {self.current_key_index} å¯ç”¨")
                    self.first_actual_call = False
                elif time_since_last_use < 60:
                    wait_time = 60 - time_since_last_use
                    logger.info(
                        f"å¯†é’¥ {self.current_key_index} éœ€è¦ç­‰å¾…: {wait_time:.1f}s"
                    )
                    time.sleep(wait_time)

                logger.info(f"å¯†é’¥ {self.current_key_index} å¯ç”¨")
                self.key_last_used_time[next_key] = current_time
                self._configure_client()
                return
            else:
                logger.info(
                    f"å¯†é’¥ {self.current_key_index} å†·å´ä¸­: å‰©ä½™ {cooldown_remaining:.1f}s"
                )

        max_cooldown = max(self.key_cooldown_until.values(), default=0) - current_time
        if max_cooldown > 0:
            logger.warning(f"æ‰€æœ‰å¯†é’¥ä¸å¯ç”¨ï¼Œç­‰å¾…æœ€é•¿å†·å´æ—¶é—´: {max_cooldown:.1f}s")
            time.sleep(max_cooldown)
            self._rotate_key(force_rotate=True)

    def _extract_retry_delay(self, error_msg: str) -> Optional[int]:
        """ä»é”™è¯¯æ¶ˆæ¯ä¸­æå–é‡è¯•å»¶è¿Ÿæ—¶é—´"""
        import re

        # å°è¯•åŒ¹é… "Please try again in Xs" æ ¼å¼
        retry_match = re.search(r"try again in (\d+)s", error_msg.lower())
        if retry_match:
            try:
                return int(retry_match.group(1))
            except ValueError:
                pass
        return None
