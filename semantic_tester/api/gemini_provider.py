"""
Gemini AI ä¾›åº”å•†å®ç°

å®ç° Gemini API çš„è¯­ä¹‰ç›¸ä¼¼åº¦æ£€æŸ¥åŠŸèƒ½ï¼Œç»§æ‰¿è‡ª AIProvider æŠ½è±¡åŸºç±»ã€‚
"""

import json
import logging
import re
import time
import threading
from typing import List, Dict, Optional, Any

try:
    import google.api_core.exceptions
    from google import genai
    from google.genai import types
except ImportError as e:
    # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ä»¥ä¾¿è¯Šæ–­æ‰“åŒ…é—®é¢˜
    import sys
    error_details = f"åŸå§‹é”™è¯¯: {type(e).__name__}: {e}"
    if hasattr(sys, '_MEIPASS'):
        # åœ¨ PyInstaller æ‰“åŒ…ç¯å¢ƒä¸­
        error_details += f"\n[PyInstaller ç¯å¢ƒ] åŸºç¡€è·¯å¾„: {sys._MEIPASS}"
    raise ImportError(
        f"è¯·å®‰è£… Google Generative AI SDK: pip install google-genai\n{error_details}"
    ) from e

try:
    from colorama import Fore, Style  # type: ignore
except ImportError:
    # å¦‚æœ colorama ä¸å¯ç”¨ï¼Œå®šä¹‰ç©ºçš„é¢œè‰²å’Œæ ·å¼
    class Fore:  # type: ignore[no-redef]
        GREEN = ""
        RED = ""

    class Style:  # type: ignore[no-redef]
        BRIGHT = ""
        RESET_ALL = ""


from .base_provider import AIProvider


from .prompts import SEMANTIC_CHECK_PROMPT

logger = logging.getLogger(__name__)


class GeminiProvider(AIProvider):
    """Gemini AI ä¾›åº”å•†"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ– Gemini ä¾›åº”å•†

        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å« api_keys, model ç­‰ä¿¡æ¯
        """
        super().__init__(config)

        self.api_keys = config.get("api_keys", [])
        self.model_name = config.get("model", "gemini-2.5-flash")

        # å†…éƒ¨çŠ¶æ€
        self.client = None
        self.current_key_index = 0
        self.key_last_used_time: Dict[str, float] = {}
        self.key_cooldown_until: Dict[str, float] = {}
        self.first_actual_call = True
        self.lock = threading.Lock()  # ç”¨äºå¤šçº¿ç¨‹å¹¶å‘ä¸‹çš„ Key è½®è½¬åŒæ­¥

        # åˆå§‹åŒ–å¯ç”¨å¯†é’¥å’Œå®¢æˆ·ç«¯
        self._initialize_api_keys()
        self._configure_client()

    def get_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        return [
            "gemini-2.5-flash",
            "gemini-2.5-pro",
            "gemini-2.0-flash-thinking-exp-1219",  # æ”¯æŒæ€ç»´é“¾çš„æ¨¡å‹
            "gemini-1.5-flash",
            "gemini-1.5-pro",
        ]

    def validate_api_key(self, api_key: str) -> bool:
        """
        éªŒè¯ API å¯†é’¥æœ‰æ•ˆæ€§

        Args:
            api_key: API å¯†é’¥

        Returns:
            bool: å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
        """
        if not re.match(r"^[a-zA-Z0-9_-]{20,}$", api_key):
            logger.warning(f"API Keyæ ¼å¼æ— æ•ˆ: {api_key[:5]}...")
            return False

        try:
            client = genai.Client(api_key=api_key)
            model_info = client.models.get(model="gemini-2.5-flash")  # type: ignore
            return model_info is not None
        except Exception:
            return False

    def is_configured(self) -> bool:
        """æ£€æŸ¥ä¾›åº”å•†æ˜¯å¦å·²æ­£ç¡®é…ç½®"""
        return len(self.api_keys) > 0 and self.client is not None

    def check_semantic_similarity(
        self,
        question: str,
        ai_answer: str,
        source_document: str,
        model: Optional[str] = None,
        stream: bool = False,
        show_thinking: bool = False,
    ) -> tuple[str, str]:
        """
        æ‰§è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦æ£€æŸ¥

        Args:
            question: é—®é¢˜å†…å®¹
            ai_answer: AIå›ç­”å†…å®¹
            source_document: æºæ–‡æ¡£å†…å®¹
            model: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            show_thinking: æ˜¯å¦æ˜¾ç¤ºæ€ç»´é“¾ï¼ˆä»…æ€è€ƒæ¨¡å‹æœ‰æ•ˆï¼‰

        Returns:
            tuple[str, str]: (ç»“æœ, åŸå› )ï¼Œç»“æœä¸º"æ˜¯"/"å¦"/"é”™è¯¯"
        """
        if not self.is_configured():
            return "é”™è¯¯", "Gemini ä¾›åº”å•†æœªæ­£ç¡®é…ç½®"

        model_to_use = model or self.model_name
        prompt = self._get_prompt(question, ai_answer, source_document)

        max_retries = 5
        default_retry_delay = 60

        for attempt in range(max_retries):
            # è·å–å¯ç”¨å®¢æˆ·ç«¯
            if not self._get_available_client():
                if not self._handle_no_client(
                    attempt, max_retries, default_retry_delay
                ):
                    return "é”™è¯¯", "æ— å¯ç”¨ Gemini æ¨¡å‹"
                continue

            # åˆ›å»ºç­‰å¾…æŒ‡ç¤ºå™¨
            stop_event = threading.Event()
            waiting_thread = threading.Thread(
                target=self.show_waiting_indicator, args=(stop_event,)
            )
            waiting_thread.daemon = True

            # åªæœ‰åœ¨éæµå¼æ¨¡å¼æ‰æ˜¾ç¤ºç­‰å¾…æŒ‡ç¤ºå™¨
            if not stream:
                waiting_thread.start()

            try:
                result, reason = self._call_gemini_api(
                    model_to_use,
                    prompt,
                    attempt,
                    max_retries,
                    stream,
                    show_thinking,
                    stop_event,
                )
                if result != "RETRY":
                    return result, reason

            except Exception as e:
                if not self._handle_general_error(
                    e, attempt, max_retries, default_retry_delay
                ):
                    return "é”™è¯¯", f"API è°ƒç”¨å¤šæ¬¡é‡è¯•å¤±è´¥: {str(e)}"
                continue

            finally:
                stop_event.set()
                if waiting_thread.is_alive():
                    waiting_thread.join(timeout=0.5)

        return "é”™è¯¯", "API è°ƒç”¨å¤šæ¬¡é‡è¯•å¤±è´¥"

    def _handle_no_client(
        self, attempt: int, max_retries: int, default_retry_delay: int
    ) -> bool:
        """
        å¤„ç†æ— å¯ç”¨å®¢æˆ·ç«¯çš„æƒ…å†µ

        Returns:
            bool: True è¡¨ç¤ºéœ€è¦é‡è¯•ï¼ŒFalse è¡¨ç¤ºåº”è¯¥è¿”å›é”™è¯¯
        """
        logger.warning("æ— å¯ç”¨ Gemini å®¢æˆ·ç«¯ï¼Œè·³è¿‡ API è°ƒç”¨")
        if attempt < max_retries - 1:
            time.sleep(default_retry_delay)
            return True
        return False

    def _call_gemini_api(  # noqa: C901
        self,
        model_to_use: str,
        prompt: str,
        attempt: int,
        max_retries: int,
        stream: bool = False,
        show_thinking: bool = False,
        stop_event: Optional[threading.Event] = None,
    ) -> tuple[str, str]:
        """
        è°ƒç”¨ Gemini API

        Returns:
            tuple[str, str]: (ç»“æœ, åŸå› ) æˆ– ("RETRY", "") è¡¨ç¤ºéœ€è¦é‡è¯•
        """
        import sys

        logger.info(
            f"æ­£åœ¨è°ƒç”¨ Gemini API è¿›è¡Œè¯­ä¹‰æ¯”å¯¹ (å°è¯• {attempt + 1}/{max_retries})..."
        )

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ€è€ƒæ¨¡å‹
        is_thinking_model = "thinking" in model_to_use.lower()

        try:
            if stream:
                # æµå¼è°ƒç”¨
                response = self.client.models.generate_content_stream(  # type: ignore
                    model=model_to_use,
                    contents=[prompt],
                    config=types.GenerateContentConfig(temperature=0),
                )

                # åœæ­¢ç­‰å¾…æŒ‡ç¤ºå™¨ï¼ˆå¦‚æœæœ‰ï¼‰
                if stop_event:
                    stop_event.set()

                full_response = ""
                thinking_content = ""
                first_char_printed = False

                logger.info("å¼€å§‹æ¥æ”¶æµå¼å“åº”...")

                for chunk in response:
                    if chunk.text:
                        # æµå¼è¾“å‡ºå†…å®¹
                        if not first_char_printed:
                            # å¦‚æœæ˜¯æ€è€ƒæ¨¡å‹ä¸”éœ€è¦æ˜¾ç¤ºæ€ç»´é“¾
                            if is_thinking_model and show_thinking:
                                # å°è¯•æå–æ€ç»´å†…å®¹
                                if hasattr(chunk, "candidates") and chunk.candidates:
                                    candidate = chunk.candidates[0]
                                    if hasattr(candidate, "content") and hasattr(
                                        candidate.content, "parts"
                                    ):
                                        for part in candidate.content.parts:
                                            if (
                                                hasattr(part, "thought")
                                                and part.thought
                                            ):
                                                thinking_content += getattr(
                                                    part, "text", ""
                                                )

                            sys.stdout.write(f"\r{' ' * 50}\r")  # æ¸…é™¤ç­‰å¾…æŒ‡ç¤ºå™¨
                            sys.stdout.write("Gemini: ")
                            sys.stdout.flush()
                            first_char_printed = True

                        # è¾“å‡ºå†…å®¹
                        print(chunk.text, end="", flush=True)
                        full_response += chunk.text

                # æ¢è¡Œ
                if first_char_printed:
                    print()

                # å¦‚æœæœ‰æ€ç»´å†…å®¹ä¸”éœ€è¦æ˜¾ç¤º
                if thinking_content and show_thinking:
                    from rich.panel import Panel
                    from rich.markdown import Markdown
                    from rich import print as rprint

                    rprint(
                        Panel(
                            Markdown(thinking_content),
                            title="[bold blue]ğŸ’­ æ€ç»´è¿‡ç¨‹[/bold blue]",
                            border_style="bright_cyan",
                            expand=False,
                        )
                    )

                response_text = full_response.strip()
            else:
                # éæµå¼è°ƒç”¨
                response = self.client.models.generate_content(  # type: ignore
                    model=model_to_use,
                    contents=[prompt],
                    config=types.GenerateContentConfig(temperature=0),
                )

                if response is None or response.text is None:
                    logger.warning("Gemini API è¿”å›ç©ºå“åº”")
                    return "é”™è¯¯", "API è¿”å›ç©ºå“åº”"

                # å¦‚æœæ˜¯æ€è€ƒæ¨¡å‹ï¼Œå°è¯•æå–æ€ç»´å†…å®¹
                if is_thinking_model and show_thinking:
                    try:
                        if hasattr(response, "candidates") and response.candidates:
                            candidate = response.candidates[0]
                            if hasattr(candidate, "content") and hasattr(
                                candidate.content, "parts"
                            ):
                                thinking_parts = []
                                for part in candidate.content.parts:
                                    if hasattr(part, "thought") and part.thought:
                                        thinking_parts.append(getattr(part, "text", ""))

                                if thinking_parts:
                                    thinking_content = "\n".join(thinking_parts)
                                    logger.info(f"\nğŸ’­ æ€ç»´è¿‡ç¨‹:\n{thinking_content}\n")
                    except Exception as e:
                        logger.debug(f"æå–æ€ç»´å†…å®¹å¤±è´¥: {e}")

                response_text = response.text.strip()

            # è§£æå“åº”
            if response_text.startswith("```json") and response_text.endswith("```"):
                response_text = response_text[7:-3].strip()

            try:
                parsed_response = json.loads(response_text)
                result = parsed_response.get("result", "æ— æ³•åˆ¤æ–­").strip()
                reason = parsed_response.get("reason", "æ— ").strip()

                colored_result = result
                if result == "æ˜¯":
                    colored_result = (
                        Style.BRIGHT + Fore.GREEN + result + Style.RESET_ALL
                    )
                elif result == "å¦":
                    colored_result = Style.BRIGHT + Fore.RED + result + Style.RESET_ALL

                logger.info(f"è¯­ä¹‰æ¯”å¯¹ç»“æœï¼š{colored_result}")
                return result, reason

            except json.JSONDecodeError as e:
                logger.warning(f"è§£æ JSON å¤±è´¥: {response_text}, é”™è¯¯: {e}")
                return "é”™è¯¯", f"JSON è§£æå¤±è´¥: {e}"

        except google.api_core.exceptions.ResourceExhausted as e:
            # é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œéœ€è¦é‡è¯•
            error_msg = str(e)
            logger.warning(f"Gemini API é€Ÿç‡é™åˆ¶: {error_msg}")

            if attempt < max_retries - 1:
                retry_after = self._extract_retry_delay(error_msg) or 60
                logger.info("æ£€æµ‹åˆ° 429 é”™è¯¯ï¼Œç«‹å³å¼ºåˆ¶è½®è½¬åˆ°ä¸‹ä¸€ä¸ªå¯†é’¥")
                current_key = self.api_keys[self.current_key_index]
                self.key_cooldown_until[current_key] = time.time() + retry_after
                self._rotate_key(force_rotate=True)
                return "RETRY", ""

            return "é”™è¯¯", f"API è°ƒç”¨æ¬¡æ•°è¶…é™: {error_msg}"

    def _handle_general_error(
        self, e: Exception, attempt: int, max_retries: int, default_retry_delay: int
    ) -> bool:
        """
        å¤„ç†ä¸€èˆ¬é”™è¯¯

        Returns:
            bool: True è¡¨ç¤ºéœ€è¦é‡è¯•ï¼ŒFalse è¡¨ç¤ºåº”è¯¥è¿”å›é”™è¯¯
        """
        error_msg = str(e)

        if isinstance(e, json.JSONDecodeError):
            logger.warning(f"Gemini è¿”å›çš„ JSON æ ¼å¼ä¸æ­£ç¡®ï¼Œé”™è¯¯ï¼š{error_msg}")
            return False  # JSONè§£æé”™è¯¯ä¸é‡è¯•
        elif isinstance(e, google.api_core.exceptions.ResourceExhausted):
            logger.warning(f"è°ƒç”¨ Gemini API æ—¶å‘ç”Ÿé€Ÿç‡é™åˆ¶é”™è¯¯ (429)ï¼š{error_msg}")
            if attempt < max_retries - 1:
                retry_after = (
                    self._extract_retry_delay(error_msg) or default_retry_delay
                )
                logger.info("æ£€æµ‹åˆ° 429 é”™è¯¯ï¼Œç«‹å³å¼ºåˆ¶è½®è½¬åˆ°ä¸‹ä¸€ä¸ªå¯†é’¥")
                current_key = self.api_keys[self.current_key_index]
                self.key_cooldown_until[current_key] = time.time() + retry_after
                self._rotate_key(force_rotate=True)
                return True
            return False
        else:
            logger.error(f"è°ƒç”¨ Gemini API æ—¶å‘ç”Ÿé”™è¯¯ï¼š{error_msg}")
            if attempt < max_retries - 1:
                logger.warning(f"ç­‰å¾… {default_retry_delay} ç§’åé‡è¯•")
                time.sleep(default_retry_delay)
                self._rotate_key(force_rotate=True)
                return True
            return False

    def _get_prompt(
        self, question: str, ai_answer: str, source_document_content: str
    ) -> str:
        """ç”Ÿæˆè¯­ä¹‰æ¯”å¯¹æç¤ºè¯"""
        return SEMANTIC_CHECK_PROMPT.format(
            question=question,
            ai_answer=ai_answer,
            source_document=source_document_content,
        )

    def _initialize_api_keys(self):
        """åˆå§‹åŒ– API å¯†é’¥åˆ—è¡¨ï¼ˆå¯åŠ¨æ—¶è·³è¿‡éªŒè¯ï¼‰"""
        if not self.api_keys:
            logger.debug("Gemini API å¯†é’¥æœªé…ç½®")
            return

        current_time = time.time()
        for key in self.api_keys:
            self.key_last_used_time[key] = current_time
            self.key_cooldown_until[key] = 0.0

        logger.debug(f"å·²åˆå§‹åŒ– {len(self.api_keys)} ä¸ª Gemini API å¯†é’¥")

    def _configure_client(self):
        """é…ç½® Gemini å®¢æˆ·ç«¯"""
        if not self.api_keys:
            self.client = None
            return

        current_api_key = self.api_keys[self.current_key_index]
        try:
            self.client = genai.Client(api_key=current_api_key)
            logger.debug(
                f"Gemini API å®¢æˆ·ç«¯å·²é…ç½®ï¼Œä½¿ç”¨å¯†é’¥ç´¢å¼•: {self.current_key_index}"
            )
            self.key_last_used_time[current_api_key] = time.time()
        except Exception as e:
            logger.error(f"Gemini API é…ç½®å¤±è´¥: {e}")
            self.client = None
            if self.api_keys:
                self._rotate_key(force_rotate=True)

    def _get_available_client(self):
        """è·å–å¯ç”¨çš„å®¢æˆ·ç«¯"""
        if not self.api_keys:
            return None

        self._rotate_key()
        return self.client

    def _rotate_key(self, force_rotate: bool = False):
        """è½®è½¬åˆ°ä¸‹ä¸€ä¸ª API å¯†é’¥ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        if not self.api_keys:
            return

        # ç”¨äºè®°å½•éœ€è¦åœ¨é”å¤–æ‰§è¡Œçš„ç­‰å¾…æ—¶é—´
        wait_time_outside_lock = 0.0

        with self.lock:  # ä½¿ç”¨çº¿ç¨‹é”ç¡®ä¿æ•´ä¸ªè½®è½¬è¿‡ç¨‹çš„åŸå­æ€§
            # å¦‚æœæœªå¯ç”¨è‡ªåŠ¨è½®è½¬ä¸”ä¸æ˜¯å¼ºåˆ¶è½®è½¬ï¼Œåˆ™ä¸è¿›è¡Œè½®è½¬
            if not self.auto_rotate and not force_rotate:
                return

            current_time = time.time()

            for _ in range(len(self.api_keys)):
                self.current_key_index = (self.current_key_index + 1) % len(
                    self.api_keys
                )
                next_key = self.api_keys[self.current_key_index]

                cooldown_until = self.key_cooldown_until.get(next_key, 0.0)
                cooldown_remaining = max(0.0, cooldown_until - current_time)
                time_since_last_use = current_time - self.key_last_used_time.get(
                    next_key, 0.0
                )

                if force_rotate:
                    logger.info(f"å¼ºåˆ¶è½®è½¬: æ–°å¯†é’¥ç´¢å¼•: {self.current_key_index}")
                    self.key_last_used_time[next_key] = current_time
                    self._configure_client()
                    return

                if cooldown_remaining <= 0:
                    if self.first_actual_call:
                        logger.info(f"é¦–æ¬¡å®é™…è°ƒç”¨ï¼Œå¯†é’¥ {self.current_key_index} å¯ç”¨")
                        self.first_actual_call = False
                    elif time_since_last_use < 60:
                        # è®°å½•éœ€è¦ç­‰å¾…çš„æ—¶é—´ï¼Œç¨ååœ¨é”å¤–æ‰§è¡Œ
                        wait_time_outside_lock = 60 - time_since_last_use
                        logger.info(
                            f"å¯†é’¥ {self.current_key_index} éœ€è¦ç­‰å¾…: {wait_time_outside_lock:.1f}s"
                        )

                    logger.info(f"å¯†é’¥ {self.current_key_index} å¯ç”¨")
                    self.key_last_used_time[next_key] = current_time
                    self._configure_client()
                    break  # é€€å‡ºå¾ªç¯ï¼Œç¨ååœ¨é”å¤–ç­‰å¾…
                else:
                    logger.info(
                        f"å¯†é’¥ {self.current_key_index} å†·å´ä¸­: å‰©ä½™ {cooldown_remaining:.1f}s"
                    )
            else:
                # æ‰€æœ‰å¯†é’¥éƒ½åœ¨å†·å´ä¸­
                max_cooldown = (
                    max(self.key_cooldown_until.values(), default=0) - current_time
                )
                if max_cooldown > 0:
                    wait_time_outside_lock = max_cooldown
                    logger.warning(
                        f"æ‰€æœ‰å¯†é’¥ä¸å¯ç”¨ï¼Œç­‰å¾…æœ€é•¿å†·å´æ—¶é—´: {max_cooldown:.1f}s"
                    )

        # åœ¨é”å¤–æ‰§è¡Œç­‰å¾…ï¼Œé¿å…é•¿æ—¶é—´æŒæœ‰é”é˜»å¡å…¶ä»–çº¿ç¨‹
        if wait_time_outside_lock > 0:
            time.sleep(wait_time_outside_lock)
            # ç­‰å¾…åéœ€è¦é‡æ–°å°è¯•è½®è½¬
            if (
                wait_time_outside_lock
                == max(self.key_cooldown_until.values(), default=0)
                - time.time()
                + wait_time_outside_lock
            ):
                self._rotate_key(force_rotate=True)
