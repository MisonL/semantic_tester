"""
Anthropic API ä¾›åº”å•†å®ç°

æ”¯æŒ Anthropic Claude API åŠå…¶å…¼å®¹æ¥å£ã€‚
"""

import logging
import threading
import time
from typing import Any, Dict, List, Optional

try:
    from anthropic.types import TextBlock
except ImportError:
    TextBlock = None

from .base_provider import AIProvider


from .prompts import SEMANTIC_CHECK_PROMPT

logger = logging.getLogger(__name__)


class AnthropicProvider(AIProvider):
    """Anthropic AI ä¾›åº”å•†å®ç°"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ– Anthropic ä¾›åº”å•†

        Args:
            config: ä¾›åº”å•†é…ç½®å­—å…¸
        """
        super().__init__(config)
        self.name = config.get("name", "Anthropic")
        self.id = config.get("id", "anthropic")
        self.api_keys = config.get("api_keys", [])
        self.base_url = config.get("base_url", "https://api.anthropic.com")
        self.has_config = config.get("has_config", len(self.api_keys) > 0)
        self.default_model = config.get("model", "claude-sonnet-4-20250514")
        self.timeout = config.get("timeout", 60)
        self.retry_count = config.get("retry_count", 3)
        self.retry_delay = config.get("retry_delay", 1)

        # å†…éƒ¨çŠ¶æ€
        self.client = None
        self.current_key_index = 0
        self.key_last_used_time: Dict[str, float] = {}
        self.key_cooldown_until: Dict[str, float] = {}
        self.first_actual_call = True

        # æ‰¹é‡å¤„ç†é…ç½®
        self.batch_config = config.get("batch", {})

        # åˆå§‹åŒ–å¯ç”¨å¯†é’¥å’Œå®¢æˆ·ç«¯
        self._initialize_api_keys()
        self._configure_client()

    def get_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹åˆ—è¡¨
        import os
        from semantic_tester.config.env_loader import get_env_loader

        models_str = os.getenv("ANTHROPIC_MODELS") or get_env_loader().get_str(
            "ANTHROPIC_MODELS", ""
        )
        if models_str:
            return [model.strip() for model in models_str.split(",") if model.strip()]

        # é»˜è®¤æ¨¡å‹åˆ—è¡¨
        return [
            "claude-sonnet-4-20250514",
            "claude-3-7-sonnet-20250314",  # æ”¯æŒExtended Thinking
            "claude-3-5-sonnet-20241022",
            "claude-3-5-haiku-20241022",
            "claude-3-opus-20240229",
        ]

    def validate_api_key(self, api_key: str) -> bool:
        """
        éªŒè¯APIå¯†é’¥æœ‰æ•ˆæ€§

        Args:
            api_key: APIå¯†é’¥

        Returns:
            bool: å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            import anthropic

            client = anthropic.Anthropic(api_key=api_key, timeout=5)
            # å‘é€ç®€å•çš„æµ‹è¯•è¯·æ±‚
            if hasattr(client, "messages") and hasattr(client.messages, "create"):
                client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=5,
                    messages=[{"role": "user", "content": "Hi"}],
                )
            return True
        except Exception:
            return False

    def check_semantic_similarity(
        self,
        question: str,
        ai_answer: str,
        source_document: str,
        model: Optional[str] = None,
        stream: bool = False,
        show_thinking: bool = False,
    ) -> tuple[str, str]:
        """
        æ‰§è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦æ£€æŸ¥

        Args:
            question: é—®é¢˜å†…å®¹
            ai_answer: AIå›ç­”å†…å®¹
            source_document: æºæ–‡æ¡£å†…å®¹
            model: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            show_thinking: æ˜¯å¦æ˜¾ç¤ºExtended Thinkingè¿‡ç¨‹

        Returns:
            tuple[str, str]: (ç»“æœ, åŸå› )ï¼Œç»“æœä¸º"æ˜¯"/"å¦"/"é”™è¯¯"
        """
        result = self.analyze_semantic(
            question, ai_answer, source_document, model, stream, show_thinking
        )
        if result["success"]:
            is_consistent = "æ˜¯" if result["is_consistent"] else "å¦"
            return is_consistent, result["reason"]
        else:
            return "é”™è¯¯", result.get("error", "æœªçŸ¥é”™è¯¯")

    def is_configured(self) -> bool:
        """
        æ£€æŸ¥ä¾›åº”å•†æ˜¯å¦å·²é…ç½®

        Returns:
            bool: æ˜¯å¦å·²é…ç½®
        """
        return len(self.api_keys) > 0 and self.client is not None

    def get_provider_info(self) -> Dict[str, Any]:
        """
        è·å–ä¾›åº”å•†ä¿¡æ¯

        Returns:
            Dict[str, Any]: ä¾›åº”å•†ä¿¡æ¯
        """
        return {
            "name": self.name,
            "id": self.id,
            "type": "anthropic",
            "configured": self.is_configured(),
            "default_model": self.default_model,
            "model": self.default_model,  # ä¿æŒå‘åå…¼å®¹
            "models": self.get_models(),
            "base_url": self.base_url,
            "features": ["è¯­ä¹‰åˆ†æ", "æ–‡æœ¬ç”Ÿæˆ"],
        }

    def test_connection(self) -> Dict[str, Any]:
        """
        æµ‹è¯•è¿æ¥

        Returns:
            Dict[str, Any]: æµ‹è¯•ç»“æœ
        """
        if not self.is_configured():
            return {
                "success": False,
                "error": "ä¾›åº”å•†æœªé…ç½®æˆ–APIå¯†é’¥æ— æ•ˆ",
                "error_type": "configuration_error",
            }

        try:
            import anthropic

            # è·å–å½“å‰APIå¯†é’¥
            current_api_key = (
                self.api_keys[self.current_key_index] if self.api_keys else ""
            )

            client = anthropic.Anthropic(
                api_key=current_api_key,
                base_url=self.base_url,
                timeout=self.timeout,
            )

            # å‘é€ç®€å•çš„æµ‹è¯•è¯·æ±‚
            if hasattr(client, "messages") and hasattr(client.messages, "create"):
                client.messages.create(
                    model=self.default_model,
                    max_tokens=10,
                    messages=[{"role": "user", "content": "Hi"}],
                )

            return {
                "success": True,
                "response_time": 0.5,  # ç®€åŒ–çš„å“åº”æ—¶é—´
                "model": self.default_model,
            }

        except ImportError:
            return {
                "success": False,
                "error": "æœªå®‰è£… anthropic åº“ï¼Œè¯·è¿è¡Œ: uv add anthropic",
                "error_type": "missing_dependency",
            }
        except Exception as e:
            logger.error(f"Anthropic è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "error_type": "api_error",
            }

    def analyze_semantic(  # noqa: C901
        self,
        question: str,
        answer: str,
        knowledge: str,
        model: Optional[str] = None,
        stream: bool = False,
        show_thinking: bool = False,
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œè¯­ä¹‰åˆ†æ

        Args:
            question: ç”¨æˆ·é—®é¢˜
            answer: AIå›ç­”
            knowledge: çŸ¥è¯†åº“æ–‡æ¡£å†…å®¹
            model: æ¨¡å‹åç§°
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            show_thinking: æ˜¯å¦æ˜¾ç¤ºExtended Thinking

        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        import sys

        if not self.is_configured():
            return {
                "success": False,
                "error": "Anthropic API æœªé…ç½®",
                "is_consistent": False,
                "confidence": 0.0,
                "reason": "ä¾›åº”å•†æœªé…ç½®",
            }

        try:
            import anthropic

            # è·å–å½“å‰APIå¯†é’¥
            current_api_key = (
                self.api_keys[self.current_key_index] if self.api_keys else ""
            )

            client = anthropic.Anthropic(
                api_key=current_api_key,
                base_url=self.base_url,
                timeout=self.timeout,
            )

            # æ„å»ºåˆ†ææç¤º
            prompt = self._build_analysis_prompt(question, answer, knowledge)

            # ä½¿ç”¨æŒ‡å®šæ¨¡å‹æˆ–é»˜è®¤æ¨¡å‹
            model_to_use = model or self.default_model

            # æ£€æŸ¥æ˜¯å¦æ”¯æŒExtended Thinking
            supports_thinking = "claude-3-7" in model_to_use.lower()

            # åˆ›å»ºç­‰å¾…æŒ‡ç¤ºå™¨
            stop_event = threading.Event()
            waiting_thread = threading.Thread(
                target=self.show_waiting_indicator, args=(stop_event,)
            )
            waiting_thread.daemon = True

            # åªåœ¨éæµå¼æ¨¡å¼æ˜¾ç¤ºç­‰å¾…æŒ‡ç¤ºå™¨
            if not stream:
                waiting_thread.start()

            try:
                start_time = time.time()

                if stream:
                    # æµå¼è°ƒç”¨
                    if stop_event:
                        stop_event.set()

                    full_response = ""
                    thinking_content = ""
                    first_char_printed = False

                    logger.info("å¼€å§‹æ¥æ”¶Anthropicæµå¼å“åº”...")

                    # å‡†å¤‡è¯·æ±‚å‚æ•°
                    create_kwargs = {
                        "model": model_to_use,
                        "max_tokens": 1000,
                        "messages": [{"role": "user", "content": prompt}],
                    }

                    # å¦‚æœæ”¯æŒä¸”éœ€è¦æ˜¾ç¤ºæ€ç»´é“¾
                    if supports_thinking and show_thinking:
                        create_kwargs["thinking"] = {
                            "type": "enabled",
                            "budget_tokens": 2000,
                        }

                    with client.messages.stream(**create_kwargs) as stream_response:
                        for text in stream_response.text_stream:
                            if not first_char_printed:
                                sys.stdout.write(f"\r{' ' * 50}\r")
                                sys.stdout.write("Anthropic: ")
                                sys.stdout.flush()
                                first_char_printed = True

                            print(text, end="", flush=True)
                            full_response += text

                    if first_char_printed:
                        print()

                    # è·å–æœ€ç»ˆæ¶ˆæ¯ä»¥æå–æ€ç»´å†…å®¹
                    final_message = stream_response.get_final_message()

                    # æå–æ€ç»´å†…å®¹
                    if (
                        supports_thinking
                        and show_thinking
                        and hasattr(final_message, "content")
                    ):
                        for block in final_message.content:
                            if hasattr(block, "type") and block.type == "thinking":
                                thinking_content = getattr(block, "thinking", "")
                                if thinking_content:
                                    from rich.panel import Panel
                                    from rich.markdown import Markdown
                                    from rich import print as rprint
                                    
                                    rprint(Panel(
                                        Markdown(thinking_content),
                                        title="[bold blue]ğŸ’­ Extended Thinking[/bold blue]",
                                        border_style="bright_cyan",
                                        expand=False
                                    ))

                    response_time = time.time() - start_time
                    text_content = full_response

                else:
                    # éæµå¼è°ƒç”¨
                    if hasattr(client, "messages") and hasattr(
                        client.messages, "create"
                    ):
                        create_kwargs = {
                            "model": model_to_use,
                            "max_tokens": 1000,
                            "messages": [{"role": "user", "content": prompt}],
                        }

                        # å¦‚æœæ”¯æŒä¸”éœ€è¦æ˜¾ç¤ºæ€ç»´é“¾
                        if supports_thinking and show_thinking:
                            create_kwargs["thinking"] = {
                                "type": "enabled",
                                "budget_tokens": 2000,
                            }

                        response = client.messages.create(**create_kwargs)
                    else:
                        raise Exception("å®¢æˆ·ç«¯æœªæ­£ç¡®åˆå§‹åŒ–")

                    response_time = time.time() - start_time

                    # è§£æå“åº” - æå–æ–‡æœ¬å†…å®¹å—
                    text_content = ""
                    thinking_content = ""

                    if hasattr(response, "content"):
                        for content_block in response.content:
                            # æå–æ€ç»´å†…å®¹
                            if supports_thinking and show_thinking:
                                if (
                                    hasattr(content_block, "type")
                                    and content_block.type == "thinking"
                                ):
                                    thinking_content = getattr(
                                        content_block, "thinking", ""
                                    )
                                    if thinking_content:
                                        from rich.panel import Panel
                                        from rich.markdown import Markdown
                                        from rich import print as rprint
                                        
                                        rprint(Panel(
                                            Markdown(thinking_content),
                                            title="[bold blue]ğŸ’­ Extended Thinking[/bold blue]",
                                            border_style="blue",
                                            expand=False
                                        ))

                            # æå–æ–‡æœ¬å†…å®¹
                            if TextBlock is not None and isinstance(
                                content_block, TextBlock
                            ):
                                text_content += content_block.text

            finally:
                # åœæ­¢ç­‰å¾…æŒ‡ç¤ºå™¨
                stop_event.set()
                if waiting_thread.is_alive():
                    waiting_thread.join(timeout=0.5)

            if not text_content:
                return {
                    "success": False,
                    "error": "å“åº”ä¸­æœªæ‰¾åˆ°æ–‡æœ¬å†…å®¹",
                    "is_consistent": False,
                    "confidence": 0.0,
                    "reason": "APIè¿”å›å“åº”ä¸åŒ…å«å¯è§£æçš„æ–‡æœ¬å†…å®¹",
                }

            result = self._parse_response(text_content)
            result["response_time"] = response_time
            result["model"] = model_to_use

            return result

        except ImportError:
            logger.error("æœªå®‰è£… anthropic åº“")
            return {
                "success": False,
                "error": "æœªå®‰è£… anthropic åº“ï¼Œè¯·è¿è¡Œ: uv add anthropic",
                "is_consistent": False,
                "confidence": 0.0,
                "reason": "ç¼ºå°‘ä¾èµ–",
            }
        except Exception as e:
            logger.error(f"Anthropic è¯­ä¹‰åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "is_consistent": False,
                "confidence": 0.0,
                "reason": f"APIè°ƒç”¨å¤±è´¥: {str(e)}",
            }

    def _build_analysis_prompt(self, question: str, answer: str, knowledge: str) -> str:
        """
        æ„å»ºåˆ†ææç¤º

        Args:
            question: ç”¨æˆ·é—®é¢˜
            answer: AIå›ç­”
            knowledge: çŸ¥è¯†åº“æ–‡æ¡£å†…å®¹

        Returns:
            str: åˆ†ææç¤º
        """
        return SEMANTIC_CHECK_PROMPT.format(
            question=question,
            ai_answer=answer,
            source_document=knowledge,
        )

    def _parse_response(self, response_text: str) -> Dict[str, Any]:
        """
        è§£æ API å“åº”

        Args:
            response_text: API å“åº”æ–‡æœ¬

        Returns:
            Dict[str, Any]: è§£æç»“æœ
        """
        import json

        try:
            # å°è¯•è§£æ JSON
            clean_text = response_text.strip()
            if clean_text.startswith("```json"):
                clean_text = clean_text[7:]
            if clean_text.startswith("```"):
                clean_text = clean_text.strip("`")
            clean_text = clean_text.strip()

            data = json.loads(clean_text)
            result = data.get("result", "æ— æ³•åˆ¤æ–­")
            reason = data.get("reason", "æ— ")

            is_consistent = result == "æ˜¯"

            return {
                "success": True,
                "is_consistent": is_consistent,
                "confidence": 1.0,  # JSON æ¨¡å¼æš‚ä¸è¿”å›ç½®ä¿¡åº¦
                "reason": reason,
                "raw_response": response_text,
            }

        except json.JSONDecodeError:
            # JSON è§£æå¤±è´¥ï¼Œå°è¯•å›é€€åˆ°æ–‡æœ¬è§£æï¼ˆå…¼å®¹æ—§æ ¼å¼æˆ–é JSON è¾“å‡ºï¼‰
            logger.warning("Anthropic å“åº”éæ ‡å‡† JSONï¼Œå°è¯•æ–‡æœ¬è§£æ")

            # é»˜è®¤å€¼
            is_consistent = False
            confidence = 0.0
            reason = "è§£æå¤±è´¥"

            # è§£æåˆ¤æ–­ç»“æœ
            if "åˆ¤æ–­ç»“æœï¼šã€æ˜¯ã€‘" in response_text or '"result": "æ˜¯"' in response_text:
                is_consistent = True
            elif (
                "åˆ¤æ–­ç»“æœï¼šã€å¦ã€‘" in response_text or '"result": "å¦"' in response_text
            ):
                is_consistent = False

            # ç®€å•æå–åŸå› 
            reason = response_text

            return {
                "success": True,
                "is_consistent": is_consistent,
                "confidence": confidence,
                "reason": reason,
                "raw_response": response_text,
            }
        except Exception as e:
            logger.error(f"è§£æ Anthropic å“åº”å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"å“åº”è§£æå¤±è´¥: {str(e)}",
                "is_consistent": False,
                "confidence": 0.0,
                "reason": "å“åº”è§£æå¤±è´¥",
                "raw_response": response_text,
            }

    def _initialize_api_keys(self):
        """åˆå§‹åŒ– API å¯†é’¥åˆ—è¡¨ï¼ˆå¯åŠ¨æ—¶è·³è¿‡éªŒè¯ï¼‰"""
        if not self.api_keys:
            logger.debug("Anthropic API å¯†é’¥æœªé…ç½®")
            return

        current_time = time.time()
        for key in self.api_keys:
            self.key_last_used_time[key] = current_time
            self.key_cooldown_until[key] = 0.0

        logger.debug(f"å·²åˆå§‹åŒ– {len(self.api_keys)} ä¸ª Anthropic API å¯†é’¥")

    def _configure_client(self):
        """é…ç½® Anthropic å®¢æˆ·ç«¯"""
        if not self.api_keys:
            self.client = None
            return

        if self.api_keys:
            current_api_key = self.api_keys[self.current_key_index]
            try:
                import anthropic

                self.client = anthropic.Anthropic(
                    api_key=current_api_key,
                    base_url=self.base_url,
                    timeout=self.timeout,
                )
                logger.debug(
                    f"Anthropic API å®¢æˆ·ç«¯å·²é…ç½®ï¼Œä½¿ç”¨å¯†é’¥ç´¢å¼•: {self.current_key_index}"
                )
                self.key_last_used_time[current_api_key] = time.time()
            except Exception as e:
                logger.error(f"Anthropic API é…ç½®å¤±è´¥: {e}")
                self.client = None
                self._rotate_key(force_rotate=True)

    def _get_available_client(self):
        """è·å–å¯ç”¨çš„å®¢æˆ·ç«¯"""
        if not self.api_keys:
            return None

        self._rotate_key()
        return self.client

    def _rotate_key(self, force_rotate: bool = False):
        """è½®è½¬åˆ°ä¸‹ä¸€ä¸ª API å¯†é’¥"""
        if not self.api_keys:
            return

        # å¦‚æœæœªå¯ç”¨è‡ªåŠ¨è½®è½¬ä¸”ä¸æ˜¯å¼ºåˆ¶è½®è½¬ï¼Œåˆ™ä¸è¿›è¡Œè½®è½¬
        if not self.auto_rotate and not force_rotate:
            return

        current_time = time.time()

        for _ in range(len(self.api_keys)):
            self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
            next_key = self.api_keys[self.current_key_index]

            cooldown_until = self.key_cooldown_until.get(next_key, 0.0)
            cooldown_remaining = max(0.0, cooldown_until - current_time)
            time_since_last_use = current_time - self.key_last_used_time.get(
                next_key, 0.0
            )

            if force_rotate:
                logger.info(f"å¼ºåˆ¶è½®è½¬: æ–°å¯†é’¥ç´¢å¼•: {self.current_key_index}")
                self.key_last_used_time[next_key] = current_time
                self._configure_client()
                return

            if cooldown_remaining <= 0:
                if self.first_actual_call:
                    logger.info(f"é¦–æ¬¡å®é™…è°ƒç”¨ï¼Œå¯†é’¥ {self.current_key_index} å¯ç”¨")
                    self.first_actual_call = False
                elif time_since_last_use < 60:
                    wait_time = 60 - time_since_last_use
                    logger.info(
                        f"å¯†é’¥ {self.current_key_index} éœ€è¦ç­‰å¾…: {wait_time:.1f}s"
                    )
                    time.sleep(wait_time)

                logger.info(f"å¯†é’¥ {self.current_key_index} å¯ç”¨")
                self.key_last_used_time[next_key] = current_time
                self._configure_client()
                return
            else:
                logger.info(
                    f"å¯†é’¥ {self.current_key_index} å†·å´ä¸­: å‰©ä½™ {cooldown_remaining:.1f}s"
                )

        max_cooldown = max(self.key_cooldown_until.values(), default=0) - current_time
        if max_cooldown > 0:
            logger.warning(f"æ‰€æœ‰å¯†é’¥ä¸å¯ç”¨ï¼Œç­‰å¾…æœ€é•¿å†·å´æ—¶é—´: {max_cooldown:.1f}s")
            time.sleep(max_cooldown)
            self._rotate_key(force_rotate=True)

    def batch_analyze(self, items: list, progress_callback=None) -> list:
        """
        æ‰¹é‡è¯­ä¹‰åˆ†æ

        Args:
            items: å¾…åˆ†æçš„é¡¹ç›®åˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            list: åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        total = len(items)

        for i, item in enumerate(items, 1):
            try:
                result = self.analyze_semantic(
                    item["question"], item["answer"], item["knowledge"]
                )
                result["row_number"] = item.get("row_number", i)
                results.append(result)

                # è°ƒç”¨è¿›åº¦å›è°ƒ
                if progress_callback:
                    progress_callback(i, total, result)

                # æ‰¹é‡å¤„ç†é—´éš”
                if i < total:
                    time.sleep(self.batch_config.get("request_interval", 1.0))

            except Exception as e:
                logger.error(f"æ‰¹é‡åˆ†æç¬¬ {i} é¡¹å¤±è´¥: {e}")
                error_result = {
                    "success": False,
                    "error": str(e),
                    "is_consistent": False,
                    "confidence": 0.0,
                    "reason": f"å¤„ç†å¤±è´¥: {str(e)}",
                    "row_number": item.get("row_number", i),
                }
                results.append(error_result)

        return results
